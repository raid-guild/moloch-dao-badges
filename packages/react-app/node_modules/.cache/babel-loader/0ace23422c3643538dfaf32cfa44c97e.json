{"ast":null,"code":"'use strict';\n\nconst pMap = require('p-map');\n\nconst GSet = require('./g-set');\n\nconst Entry = require('./entry');\n\nconst LogIO = require('./log-io');\n\nconst LogError = require('./log-errors');\n\nconst Clock = require('./lamport-clock');\n\nconst Sorting = require('./log-sorting');\n\nconst {\n  LastWriteWins,\n  NoZeroes\n} = Sorting;\n\nconst AccessController = require('./default-access-controller');\n\nconst {\n  isDefined,\n  findUniques\n} = require('./utils');\n\nconst EntryIndex = require('./entry-index');\n\nconst randomId = () => new Date().getTime().toString();\n\nconst getHash = e => e.hash;\n\nconst flatMap = (res, acc) => res.concat(acc);\n\nconst getNextPointers = entry => entry.next;\n\nconst maxClockTimeReducer = (res, acc) => Math.max(res, acc.clock.time);\n\nconst uniqueEntriesReducer = (res, acc) => {\n  res[acc.hash] = acc;\n  return res;\n};\n/**\n * Log.\n *\n * @description\n * Log implements a G-Set CRDT and adds ordering.\n *\n * From:\n * \"A comprehensive study of Convergent and Commutative Replicated Data Types\"\n * https://hal.inria.fr/inria-00555588\n */\n\n\nclass Log extends GSet {\n  /**\n   * Create a new Log instance\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {Object} identity Identity (https://github.com/orbitdb/orbit-db-identity-provider/blob/master/src/identity.js)\n   * @param {Object} options\n   * @param {string} options.logId ID of the log\n   * @param {Object} options.access AccessController (./default-access-controller)\n   * @param {Array<Entry>} options.entries An Array of Entries from which to create the log\n   * @param {Array<Entry>} options.heads Set the heads of the log\n   * @param {Clock} options.clock Set the clock of the log\n   * @param {Function} options.sortFn The sort function - by default LastWriteWins\n   * @return {Log} The log instance\n   */\n  constructor(ipfs, identity, {\n    logId,\n    access,\n    entries,\n    heads,\n    clock,\n    sortFn,\n    concurrency\n  } = {}) {\n    if (!isDefined(ipfs)) {\n      throw LogError.IPFSNotDefinedError();\n    }\n\n    if (!isDefined(identity)) {\n      throw new Error('Identity is required');\n    }\n\n    if (!isDefined(access)) {\n      access = new AccessController();\n    }\n\n    if (isDefined(entries) && !Array.isArray(entries)) {\n      throw new Error(`'entries' argument must be an array of Entry instances`);\n    }\n\n    if (isDefined(heads) && !Array.isArray(heads)) {\n      throw new Error(`'heads' argument must be an array`);\n    }\n\n    if (!isDefined(sortFn)) {\n      sortFn = LastWriteWins;\n    }\n\n    super();\n    this._sortFn = NoZeroes(sortFn);\n    this._storage = ipfs;\n    this._id = logId || randomId(); // Access Controller\n\n    this._access = access; // Identity\n\n    this._identity = identity; // Add entries to the internal cache\n\n    const uniqueEntries = (entries || []).reduce(uniqueEntriesReducer, {});\n    this._entryIndex = new EntryIndex(uniqueEntries);\n    entries = Object.values(uniqueEntries) || []; // Set heads if not passed as an argument\n\n    heads = heads || Log.findHeads(entries);\n    this._headsIndex = heads.reduce(uniqueEntriesReducer, {}); // Index of all next pointers in this log\n\n    this._nextsIndex = {};\n\n    const addToNextsIndex = e => e.next.forEach(a => this._nextsIndex[a] = e.hash);\n\n    entries.forEach(addToNextsIndex); // Set the length, we calculate the length manually internally\n\n    this._length = entries.length; // Set the clock\n\n    const maxTime = Math.max(clock ? clock.time : 0, this.heads.reduce(maxClockTimeReducer, 0)); // Take the given key as the clock id is it's a Key instance,\n    // otherwise if key was given, take whatever it is,\n    // and if it was null, take the given id as the clock id\n\n    this._clock = new Clock(this._identity.publicKey, maxTime);\n    this.joinConcurrency = concurrency || 16;\n  }\n  /**\n   * Returns the ID of the log.\n   * @returns {string}\n   */\n\n\n  get id() {\n    return this._id;\n  }\n  /**\n   * Returns the clock of the log.\n   * @returns {string}\n   */\n\n\n  get clock() {\n    return this._clock;\n  }\n  /**\n   * Returns the length of the log.\n   * @return {number} Length\n   */\n\n\n  get length() {\n    return this._length;\n  }\n  /**\n   * Returns the values in the log.\n   * @returns {Array<Entry>}\n   */\n\n\n  get values() {\n    return Object.values(this.traverse(this.heads)).reverse();\n  }\n  /**\n   * Returns an array of heads as hashes.\n   * @returns {Array<string>}\n   */\n\n\n  get heads() {\n    return Object.values(this._headsIndex).sort(this._sortFn).reverse();\n  }\n  /**\n   * Returns an array of Entry objects that reference entries which\n   * are not in the log currently.\n   * @returns {Array<Entry>}\n   */\n\n\n  get tails() {\n    return Log.findTails(this.values);\n  }\n  /**\n   * Returns an array of hashes that are referenced by entries which\n   * are not in the log currently.\n   * @returns {Array<string>} Array of hashes\n   */\n\n\n  get tailHashes() {\n    return Log.findTailHashes(this.values);\n  }\n  /**\n   * Set the identity for the log\n   * @param {Identity} [identity] The identity to be set\n   */\n\n\n  setIdentity(identity) {\n    this._identity = identity; // Find the latest clock from the heads\n\n    const time = Math.max(this.clock.time, this.heads.reduce(maxClockTimeReducer, 0));\n    this._clock = new Clock(this._identity.publicKey, time);\n  }\n  /**\n   * Find an entry.\n   * @param {string} [hash] The hashes of the entry\n   * @returns {Entry|undefined}\n   */\n\n\n  get(hash) {\n    return this._entryIndex.get(hash);\n  }\n  /**\n   * Checks if a entry is part of the log\n   * @param {string} hash The hash of the entry\n   * @returns {boolean}\n   */\n\n\n  has(entry) {\n    return this._entryIndex.get(entry.hash || entry) !== undefined;\n  }\n\n  traverse(rootEntries, amount = -1, endHash) {\n    // Sort the given given root entries and use as the starting stack\n    let stack = rootEntries.sort(this._sortFn).reverse(); // Cache for checking if we've processed an entry already\n\n    let traversed = {}; // End result\n\n    let result = {};\n    let count = 0; // Named function for getting an entry from the log\n\n    const getEntry = e => this.get(e); // Add an entry to the stack and traversed nodes index\n\n\n    const addToStack = entry => {\n      // If we've already processed the entry, don't add it to the stack\n      if (!entry || traversed[entry.hash]) {\n        return;\n      } // Add the entry in front of the stack and sort\n\n\n      stack = [entry, ...stack].sort(this._sortFn).reverse(); // Add to the cache of processed entries\n\n      traversed[entry.hash] = true;\n    };\n\n    const addEntry = rootEntry => {\n      result[rootEntry.hash] = rootEntry;\n      traversed[rootEntry.hash] = true;\n      count++;\n    }; // Start traversal\n    // Process stack until it's empty (traversed the full log)\n    // or when we have the requested amount of entries\n    // If requested entry amount is -1, traverse all\n\n\n    while (stack.length > 0 && (count < amount || amount < 0)) {\n      // eslint-disable-line no-unmodified-loop-condition\n      // Get the next element from the stack\n      const entry = stack.shift(); // Add to the result\n\n      addEntry(entry); // If it is the specified end hash, break out of the while loop\n\n      if (endHash && endHash === entry.hash) break; // Add entry's next references to the stack\n\n      const entries = entry.next.map(getEntry);\n      const defined = entries.filter(isDefined);\n      defined.forEach(addToStack);\n    }\n\n    stack = [];\n    traversed = {}; // End result\n\n    return result;\n  }\n  /**\n   * Append an entry to the log.\n   * @param {Entry} entry Entry to add\n   * @return {Log} New Log containing the appended value\n   */\n\n\n  async append(data, pointerCount = 1, pin = false) {\n    // Update the clock (find the latest clock)\n    const newTime = Math.max(this.clock.time, this.heads.reduce(maxClockTimeReducer, 0)) + 1;\n    this._clock = new Clock(this.clock.id, newTime);\n    const all = Object.values(this.traverse(this.heads, Math.max(pointerCount, this.heads.length))); // If pointer count is 4, returns 2\n    // If pointer count is 8, returns 3 references\n    // If pointer count is 512, returns 9 references\n    // If pointer count is 2048, returns 11 references\n\n    const getEveryPow2 = maxDistance => {\n      let entries = new Set();\n\n      for (let i = 1; i <= maxDistance; i *= 2) {\n        const index = Math.min(i - 1, all.length - 1);\n        entries.add(all[index]);\n      }\n\n      return entries;\n    };\n\n    const references = getEveryPow2(Math.min(pointerCount, all.length)); // Always include the last known reference\n\n    if (all.length < pointerCount && all[all.length - 1]) {\n      references.add(all[all.length - 1]);\n    } // Create the next pointers from heads\n\n\n    const nexts = Object.keys(this.heads.reverse().reduce(uniqueEntriesReducer, {}));\n\n    const isNext = e => !nexts.includes(e); // Delete the heads from the refs\n\n\n    const refs = Array.from(references).map(getHash).filter(isNext); // @TODO: Split Entry.create into creating object, checking permission, signing and then posting to IPFS\n    // Create the entry and add it to the internal cache\n\n    const entry = await Entry.create(this._storage, this._identity, this.id, data, nexts, this.clock, refs, pin);\n    const canAppend = await this._access.canAppend(entry, this._identity.provider);\n\n    if (!canAppend) {\n      throw new Error(`Could not append entry, key \"${this._identity.id}\" is not allowed to write to the log`);\n    }\n\n    this._entryIndex.set(entry.hash, entry);\n\n    nexts.forEach(e => this._nextsIndex[e] = entry.hash);\n    this._headsIndex = {};\n    this._headsIndex[entry.hash] = entry; // Update the length\n\n    this._length++;\n    return entry;\n  }\n  /*\n   * Creates a javscript iterator over log entries\n   *\n   * @param {Object} options\n   * @param {string|Array} options.gt Beginning hash of the iterator, non-inclusive\n   * @param {string|Array} options.gte Beginning hash of the iterator, inclusive\n   * @param {string|Array} options.lt Ending hash of the iterator, non-inclusive\n   * @param {string|Array} options.lte Ending hash of the iterator, inclusive\n   * @param {amount} options.amount Number of entried to return to / from the gte / lte hash\n   * @returns {Symbol.Iterator} Iterator object containing log entries\n   *\n   * @examples\n   *\n   * (async () => {\n   *   log1 = new Log(ipfs, testIdentity, { logId: 'X' })\n   *\n   *   for (let i = 0; i <= 100; i++) {\n   *     await log1.append('entry' + i)\n   *   }\n   *\n   *   let it = log1.iterator({\n   *     lte: 'zdpuApFd5XAPkCTmSx7qWQmQzvtdJPtx2K5p9to6ytCS79bfk',\n   *     amount: 10\n   *   })\n   *\n   *   [...it].length // 10\n   * })()\n   *\n   *\n   */\n\n\n  iterator({\n    gt = undefined,\n    gte = undefined,\n    lt = undefined,\n    lte = undefined,\n    amount = -1\n  } = {}) {\n    if (amount === 0) return function* () {}();\n    if (typeof lte === 'string') lte = [this.get(lte)];\n    if (typeof lt === 'string') lt = [this.get(this.get(lt).next)];\n    if (lte && !Array.isArray(lte)) throw LogError.LtOrLteMustBeStringOrArray();\n    if (lt && !Array.isArray(lt)) throw LogError.LtOrLteMustBeStringOrArray();\n    let start = (lte || lt || this.heads).filter(isDefined);\n    let endHash = gte ? this.get(gte).hash : gt ? this.get(gt).hash : null;\n    let count = endHash ? -1 : amount || -1;\n    let entries = this.traverse(start, count, endHash);\n    let entryValues = Object.values(entries); // Strip off last entry if gt is non-inclusive\n\n    if (gt) entryValues.pop(); // Deal with the amount argument working backwards from gt/gte\n\n    if ((gt || gte) && amount > -1) {\n      entryValues = entryValues.slice(entryValues.length - amount, entryValues.length);\n    }\n\n    return function* () {\n      for (let i in entryValues) {\n        yield entryValues[i];\n      }\n    }();\n  }\n  /**\n   * Join two logs.\n   *\n   * Joins another log into this one.\n   *\n   * @param {Log} log Log to join with this Log\n   * @param {number} [size=-1] Max size of the joined log\n   * @returns {Promise<Log>} This Log instance\n   * @example\n   * await log1.join(log2)\n   */\n\n\n  async join(log, size = -1) {\n    if (!isDefined(log)) throw LogError.LogNotDefinedError();\n    if (!Log.isLog(log)) throw LogError.NotALogError();\n    if (this.id !== log.id) return; // Get the difference of the logs\n\n    const newItems = Log.difference(log, this);\n    const identityProvider = this._identity.provider; // Verify if entries are allowed to be added to the log and throws if\n    // there's an invalid entry\n\n    const permitted = async entry => {\n      const canAppend = await this._access.canAppend(entry, identityProvider);\n\n      if (!canAppend) {\n        throw new Error(`Could not append entry, key \"${entry.identity.id}\" is not allowed to write to the log`);\n      }\n    }; // Verify signature for each entry and throws if there's an invalid signature\n\n\n    const verify = async entry => {\n      const isValid = await Entry.verify(identityProvider, entry);\n      const publicKey = entry.identity ? entry.identity.publicKey : entry.key;\n      if (!isValid) throw new Error(`Could not validate signature \"${entry.sig}\" for entry \"${entry.hash}\" and key \"${publicKey}\"`);\n    };\n\n    const entriesToJoin = Object.values(newItems);\n    await pMap(entriesToJoin, async e => {\n      await permitted(e);\n      await verify(e);\n    }, {\n      concurrency: this.joinConcurrency\n    }); // Update the internal next pointers index\n\n    const addToNextsIndex = e => {\n      const entry = this.get(e.hash);\n      if (!entry) this._length++;\n      /* istanbul ignore else */\n\n      e.next.forEach(a => this._nextsIndex[a] = e.hash);\n    };\n\n    Object.values(newItems).forEach(addToNextsIndex); // Update the internal entry index\n\n    this._entryIndex.add(newItems); // Merge the heads\n\n\n    const notReferencedByNewItems = e => !nextsFromNewItems.find(a => a === e.hash);\n\n    const notInCurrentNexts = e => !this._nextsIndex[e.hash];\n\n    const nextsFromNewItems = Object.values(newItems).map(getNextPointers).reduce(flatMap, []);\n    const mergedHeads = Log.findHeads(Object.values(Object.assign({}, this._headsIndex, log._headsIndex))).filter(notReferencedByNewItems).filter(notInCurrentNexts).reduce(uniqueEntriesReducer, {});\n    this._headsIndex = mergedHeads; // Slice to the requested size\n\n    if (size > -1) {\n      let tmp = this.values;\n      tmp = tmp.slice(-size);\n      this._entryIndex = null;\n      this._entryIndex = new EntryIndex(tmp.reduce(uniqueEntriesReducer, {}));\n      this._headsIndex = Log.findHeads(tmp).reduce(uniqueEntriesReducer, {});\n      this._length = this._entryIndex.length;\n    } // Find the latest clock from the heads\n\n\n    const maxClock = Object.values(this._headsIndex).reduce(maxClockTimeReducer, 0);\n    this._clock = new Clock(this.clock.id, Math.max(this.clock.time, maxClock));\n    return this;\n  }\n  /**\n   * Get the log in JSON format.\n   * @returns {Object} An object with the id and heads properties\n   */\n\n\n  toJSON() {\n    return {\n      id: this.id,\n      heads: this.heads.sort(this._sortFn) // default sorting\n      .reverse() // we want the latest as the first element\n      .map(getHash) // return only the head hashes\n\n    };\n  }\n  /**\n   * Get the log in JSON format as a snapshot.\n   * @returns {Object} An object with the id, heads and value properties\n   */\n\n\n  toSnapshot() {\n    return {\n      id: this.id,\n      heads: this.heads,\n      values: this.values\n    };\n  }\n  /**\n   * Get the log as a Buffer.\n   * @returns {Buffer}\n   */\n\n\n  toBuffer() {\n    return Buffer.from(JSON.stringify(this.toJSON()));\n  }\n  /**\n   * Returns the log entries as a formatted string.\n   * @returns {string}\n   * @example\n   * two\n   * └─one\n   *   └─three\n   */\n\n\n  toString(payloadMapper) {\n    return this.values.slice().reverse().map((e, idx) => {\n      const parents = Entry.findChildren(e, this.values);\n      const len = parents.length;\n      let padding = new Array(Math.max(len - 1, 0));\n      padding = len > 1 ? padding.fill('  ') : padding;\n      padding = len > 0 ? padding.concat(['└─']) : padding;\n      /* istanbul ignore next */\n\n      return padding.join('') + (payloadMapper ? payloadMapper(e.payload) : e.payload);\n    }).join('\\n');\n  }\n  /**\n   * Check whether an object is a Log instance.\n   * @param {Object} log An object to check\n   * @returns {boolean}\n   */\n\n\n  static isLog(log) {\n    return log.id !== undefined && log.heads !== undefined && log._entryIndex !== undefined;\n  }\n  /**\n   * Get the log's multihash.\n   * @returns {Promise<string>} Multihash of the Log as Base58 encoded string.\n   */\n\n\n  toMultihash({\n    format\n  } = {}) {\n    return LogIO.toMultihash(this._storage, this, {\n      format\n    });\n  }\n  /**\n   * Create a log from a hashes.\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {Identity} identity The identity instance\n   * @param {string} hash The log hash\n   * @param {Object} options\n   * @param {AccessController} options.access The access controller instance\n   * @param {number} options.length How many items to include in the log\n   * @param {Array<Entry>} options.exclude Entries to not fetch (cached)\n   * @param {function(hash, entry, parent, depth)} options.onProgressCallback\n   * @param {Function} options.sortFn The sort function - by default LastWriteWins\n   * @returns {Promise<Log>}\n   */\n\n\n  static async fromMultihash(ipfs, identity, hash, {\n    access,\n    length = -1,\n    exclude = [],\n    timeout,\n    concurrency,\n    sortFn,\n    onProgressCallback\n  } = {}) {\n    // TODO: need to verify the entries with 'key'\n    const {\n      logId,\n      entries,\n      heads\n    } = await LogIO.fromMultihash(ipfs, hash, {\n      length,\n      exclude,\n      timeout,\n      onProgressCallback,\n      concurrency,\n      sortFn\n    });\n    return new Log(ipfs, identity, {\n      logId,\n      access,\n      entries,\n      heads,\n      sortFn\n    });\n  }\n  /**\n   * Create a log from a single entry's hash.\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {Identity} identity The identity instance\n   * @param {string} hash The entry's hash\n   * @param {Object} options\n   * @param {string} options.logId The ID of the log\n   * @param {AccessController} options.access The access controller instance\n   * @param {number} options.length How many entries to include in the log\n   * @param {Array<Entry>} options.exclude Entries to not fetch (cached)\n   * @param {function(hash, entry, parent, depth)} options.onProgressCallback\n   * @param {Function} options.sortFn The sort function - by default LastWriteWins\n   * @return {Promise<Log>} New Log\n   */\n\n\n  static async fromEntryHash(ipfs, identity, hash, {\n    logId,\n    access,\n    length = -1,\n    exclude = [],\n    timeout,\n    concurrency,\n    sortFn,\n    onProgressCallback\n  } = {}) {\n    // TODO: need to verify the entries with 'key'\n    const {\n      entries\n    } = await LogIO.fromEntryHash(ipfs, hash, {\n      length,\n      exclude,\n      timeout,\n      concurrency,\n      onProgressCallback\n    });\n    return new Log(ipfs, identity, {\n      logId,\n      access,\n      entries,\n      sortFn\n    });\n  }\n  /**\n   * Create a log from a Log Snapshot JSON.\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {Identity} identity The identity instance\n   * @param {Object} json Log snapshot as JSON object\n   * @param {Object} options\n   * @param {AccessController} options.access The access controller instance\n   * @param {number} options.length How many entries to include in the log\n   * @param {function(hash, entry, parent, depth)} [options.onProgressCallback]\n   * @param {Function} options.sortFn The sort function - by default LastWriteWins\n   * @return {Promise<Log>} New Log\n   */\n\n\n  static async fromJSON(ipfs, identity, json, {\n    access,\n    length = -1,\n    timeout,\n    sortFn,\n    onProgressCallback\n  } = {}) {\n    // TODO: need to verify the entries with 'key'\n    const {\n      logId,\n      entries\n    } = await LogIO.fromJSON(ipfs, json, {\n      length,\n      timeout,\n      onProgressCallback\n    });\n    return new Log(ipfs, identity, {\n      logId,\n      access,\n      entries,\n      sortFn\n    });\n  }\n  /**\n   * Create a new log from an Entry instance.\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {Identity} identity The identity instance\n   * @param {Entry|Array<Entry>} sourceEntries An Entry or an array of entries to fetch a log from\n   * @param {Object} options\n   * @param {AccessController} options.access The access controller instance\n   * @param {number} options.length How many entries to include. Default: infinite.\n   * @param {Array<Entry>} options.exclude Entries to not fetch (cached)\n   * @param {function(hash, entry, parent, depth)} [options.onProgressCallback]\n   * @param {Function} options.sortFn The sort function - by default LastWriteWins\n   * @return {Promise<Log>} New Log\n   */\n\n\n  static async fromEntry(ipfs, identity, sourceEntries, {\n    access,\n    length = -1,\n    exclude = [],\n    timeout,\n    concurrency,\n    sortFn,\n    onProgressCallback\n  } = {}) {\n    // TODO: need to verify the entries with 'key'\n    const {\n      logId,\n      entries\n    } = await LogIO.fromEntry(ipfs, sourceEntries, {\n      length,\n      exclude,\n      timeout,\n      concurrency,\n      onProgressCallback\n    });\n    return new Log(ipfs, identity, {\n      logId,\n      access,\n      entries,\n      sortFn\n    });\n  }\n  /**\n   * Find heads from a collection of entries.\n   *\n   * Finds entries that are the heads of this collection,\n   * ie. entries that are not referenced by other entries.\n   *\n   * @param {Array<Entry>} entries Entries to search heads from\n   * @returns {Array<Entry>}\n   */\n\n\n  static findHeads(entries) {\n    var indexReducer = (res, entry, idx, arr) => {\n      var addToResult = e => res[e] = entry.hash;\n\n      entry.next.forEach(addToResult);\n      return res;\n    };\n\n    var items = entries.reduce(indexReducer, {});\n\n    var exists = e => items[e.hash] === undefined;\n\n    var compareIds = (a, b) => a.clock.id > b.clock.id;\n\n    return entries.filter(exists).sort(compareIds);\n  } // Find entries that point to another entry that is not in the\n  // input array\n\n\n  static findTails(entries) {\n    // Reverse index { next -> entry }\n    var reverseIndex = {}; // Null index containing entries that have no parents (nexts)\n\n    var nullIndex = []; // Hashes for all entries for quick lookups\n\n    var hashes = {}; // Hashes of all next entries\n\n    var nexts = [];\n\n    var addToIndex = e => {\n      if (e.next.length === 0) {\n        nullIndex.push(e);\n      }\n\n      var addToReverseIndex = a => {\n        /* istanbul ignore else */\n        if (!reverseIndex[a]) reverseIndex[a] = [];\n        reverseIndex[a].push(e);\n      }; // Add all entries and their parents to the reverse index\n\n\n      e.next.forEach(addToReverseIndex); // Get all next references\n\n      nexts = nexts.concat(e.next); // Get the hashes of input entries\n\n      hashes[e.hash] = true;\n    }; // Create our indices\n\n\n    entries.forEach(addToIndex);\n\n    var addUniques = (res, entries, idx, arr) => res.concat(findUniques(entries, 'hash'));\n\n    var exists = e => hashes[e] === undefined;\n\n    var findFromReverseIndex = e => reverseIndex[e]; // Drop hashes that are not in the input entries\n\n\n    const tails = nexts // For every hash in nexts:\n    .filter(exists) // Remove undefineds and nulls\n    .map(findFromReverseIndex) // Get the Entry from the reverse index\n    .reduce(addUniques, []) // Flatten the result and take only uniques\n    .concat(nullIndex); // Combine with tails the have no next refs (ie. first-in-their-chain)\n\n    return findUniques(tails, 'hash').sort(Entry.compare);\n  } // Find the hashes to entries that are not in a collection\n  // but referenced by other entries\n\n\n  static findTailHashes(entries) {\n    var hashes = {};\n\n    var addToIndex = e => hashes[e.hash] = true;\n\n    var reduceTailHashes = (res, entry, idx, arr) => {\n      var addToResult = e => {\n        /* istanbul ignore else */\n        if (hashes[e] === undefined) {\n          res.splice(0, 0, e);\n        }\n      };\n\n      entry.next.reverse().forEach(addToResult);\n      return res;\n    };\n\n    entries.forEach(addToIndex);\n    return entries.reduce(reduceTailHashes, []);\n  }\n\n  static difference(a, b) {\n    let stack = Object.keys(a._headsIndex);\n    let traversed = {};\n    let res = {};\n\n    const pushToStack = hash => {\n      if (!traversed[hash] && !b.get(hash)) {\n        stack.push(hash);\n        traversed[hash] = true;\n      }\n    };\n\n    while (stack.length > 0) {\n      const hash = stack.shift();\n      const entry = a.get(hash);\n\n      if (entry && !b.get(hash) && entry.id === b.id) {\n        res[entry.hash] = entry;\n        traversed[entry.hash] = true;\n        entry.next.forEach(pushToStack);\n      }\n    }\n\n    return res;\n  }\n\n}\n\nmodule.exports = Log;\nmodule.exports.Sorting = Sorting;\nmodule.exports.Entry = Entry;\nmodule.exports.AccessController = AccessController;","map":{"version":3,"sources":["/home/dekan/Projects/raid-guild/dao-badges-web/node_modules/ipfs-log/src/log.js"],"names":["pMap","require","GSet","Entry","LogIO","LogError","Clock","Sorting","LastWriteWins","NoZeroes","AccessController","isDefined","findUniques","EntryIndex","randomId","Date","getTime","toString","getHash","e","hash","flatMap","res","acc","concat","getNextPointers","entry","next","maxClockTimeReducer","Math","max","clock","time","uniqueEntriesReducer","Log","constructor","ipfs","identity","logId","access","entries","heads","sortFn","concurrency","IPFSNotDefinedError","Error","Array","isArray","_sortFn","_storage","_id","_access","_identity","uniqueEntries","reduce","_entryIndex","Object","values","findHeads","_headsIndex","_nextsIndex","addToNextsIndex","forEach","a","_length","length","maxTime","_clock","publicKey","joinConcurrency","id","traverse","reverse","sort","tails","findTails","tailHashes","findTailHashes","setIdentity","get","has","undefined","rootEntries","amount","endHash","stack","traversed","result","count","getEntry","addToStack","addEntry","rootEntry","shift","map","defined","filter","append","data","pointerCount","pin","newTime","all","getEveryPow2","maxDistance","Set","i","index","min","add","references","nexts","keys","isNext","includes","refs","from","create","canAppend","provider","set","iterator","gt","gte","lt","lte","LtOrLteMustBeStringOrArray","start","entryValues","pop","slice","join","log","size","LogNotDefinedError","isLog","NotALogError","newItems","difference","identityProvider","permitted","verify","isValid","key","sig","entriesToJoin","notReferencedByNewItems","nextsFromNewItems","find","notInCurrentNexts","mergedHeads","assign","tmp","maxClock","toJSON","toSnapshot","toBuffer","Buffer","JSON","stringify","payloadMapper","idx","parents","findChildren","len","padding","fill","payload","toMultihash","format","fromMultihash","exclude","timeout","onProgressCallback","fromEntryHash","fromJSON","json","fromEntry","sourceEntries","indexReducer","arr","addToResult","items","exists","compareIds","b","reverseIndex","nullIndex","hashes","addToIndex","push","addToReverseIndex","addUniques","findFromReverseIndex","compare","reduceTailHashes","splice","pushToStack","module","exports"],"mappings":"AAAA;;AAEA,MAAMA,IAAI,GAAGC,OAAO,CAAC,OAAD,CAApB;;AACA,MAAMC,IAAI,GAAGD,OAAO,CAAC,SAAD,CAApB;;AACA,MAAME,KAAK,GAAGF,OAAO,CAAC,SAAD,CAArB;;AACA,MAAMG,KAAK,GAAGH,OAAO,CAAC,UAAD,CAArB;;AACA,MAAMI,QAAQ,GAAGJ,OAAO,CAAC,cAAD,CAAxB;;AACA,MAAMK,KAAK,GAAGL,OAAO,CAAC,iBAAD,CAArB;;AACA,MAAMM,OAAO,GAAGN,OAAO,CAAC,eAAD,CAAvB;;AACA,MAAM;AAAEO,EAAAA,aAAF;AAAiBC,EAAAA;AAAjB,IAA8BF,OAApC;;AACA,MAAMG,gBAAgB,GAAGT,OAAO,CAAC,6BAAD,CAAhC;;AACA,MAAM;AAAEU,EAAAA,SAAF;AAAaC,EAAAA;AAAb,IAA6BX,OAAO,CAAC,SAAD,CAA1C;;AACA,MAAMY,UAAU,GAAGZ,OAAO,CAAC,eAAD,CAA1B;;AACA,MAAMa,QAAQ,GAAG,MAAM,IAAIC,IAAJ,GAAWC,OAAX,GAAqBC,QAArB,EAAvB;;AACA,MAAMC,OAAO,GAAGC,CAAC,IAAIA,CAAC,CAACC,IAAvB;;AACA,MAAMC,OAAO,GAAG,CAACC,GAAD,EAAMC,GAAN,KAAcD,GAAG,CAACE,MAAJ,CAAWD,GAAX,CAA9B;;AACA,MAAME,eAAe,GAAGC,KAAK,IAAIA,KAAK,CAACC,IAAvC;;AACA,MAAMC,mBAAmB,GAAG,CAACN,GAAD,EAAMC,GAAN,KAAcM,IAAI,CAACC,GAAL,CAASR,GAAT,EAAcC,GAAG,CAACQ,KAAJ,CAAUC,IAAxB,CAA1C;;AACA,MAAMC,oBAAoB,GAAG,CAACX,GAAD,EAAMC,GAAN,KAAc;AACzCD,EAAAA,GAAG,CAACC,GAAG,CAACH,IAAL,CAAH,GAAgBG,GAAhB;AACA,SAAOD,GAAP;AACD,CAHD;AAKA;;;;;;;;;;;;AAUA,MAAMY,GAAN,SAAkBhC,IAAlB,CAAuB;AACrB;;;;;;;;;;;;;AAaAiC,EAAAA,WAAW,CAAEC,IAAF,EAAQC,QAAR,EAAkB;AAAEC,IAAAA,KAAF;AAASC,IAAAA,MAAT;AAAiBC,IAAAA,OAAjB;AAA0BC,IAAAA,KAA1B;AAAiCV,IAAAA,KAAjC;AAAwCW,IAAAA,MAAxC;AAAgDC,IAAAA;AAAhD,MAAgE,EAAlF,EAAsF;AAC/F,QAAI,CAAChC,SAAS,CAACyB,IAAD,CAAd,EAAsB;AACpB,YAAM/B,QAAQ,CAACuC,mBAAT,EAAN;AACD;;AAED,QAAI,CAACjC,SAAS,CAAC0B,QAAD,CAAd,EAA0B;AACxB,YAAM,IAAIQ,KAAJ,CAAU,sBAAV,CAAN;AACD;;AAED,QAAI,CAAClC,SAAS,CAAC4B,MAAD,CAAd,EAAwB;AACtBA,MAAAA,MAAM,GAAG,IAAI7B,gBAAJ,EAAT;AACD;;AAED,QAAIC,SAAS,CAAC6B,OAAD,CAAT,IAAsB,CAACM,KAAK,CAACC,OAAN,CAAcP,OAAd,CAA3B,EAAmD;AACjD,YAAM,IAAIK,KAAJ,CAAW,wDAAX,CAAN;AACD;;AAED,QAAIlC,SAAS,CAAC8B,KAAD,CAAT,IAAoB,CAACK,KAAK,CAACC,OAAN,CAAcN,KAAd,CAAzB,EAA+C;AAC7C,YAAM,IAAII,KAAJ,CAAW,mCAAX,CAAN;AACD;;AAED,QAAI,CAAClC,SAAS,CAAC+B,MAAD,CAAd,EAAwB;AACtBA,MAAAA,MAAM,GAAGlC,aAAT;AACD;;AAED;AAEA,SAAKwC,OAAL,GAAevC,QAAQ,CAACiC,MAAD,CAAvB;AAEA,SAAKO,QAAL,GAAgBb,IAAhB;AACA,SAAKc,GAAL,GAAWZ,KAAK,IAAIxB,QAAQ,EAA5B,CA9B+F,CAgC/F;;AACA,SAAKqC,OAAL,GAAeZ,MAAf,CAjC+F,CAkC/F;;AACA,SAAKa,SAAL,GAAiBf,QAAjB,CAnC+F,CAqC/F;;AACA,UAAMgB,aAAa,GAAG,CAACb,OAAO,IAAI,EAAZ,EAAgBc,MAAhB,CAAuBrB,oBAAvB,EAA6C,EAA7C,CAAtB;AACA,SAAKsB,WAAL,GAAmB,IAAI1C,UAAJ,CAAewC,aAAf,CAAnB;AACAb,IAAAA,OAAO,GAAGgB,MAAM,CAACC,MAAP,CAAcJ,aAAd,KAAgC,EAA1C,CAxC+F,CA0C/F;;AACAZ,IAAAA,KAAK,GAAGA,KAAK,IAAIP,GAAG,CAACwB,SAAJ,CAAclB,OAAd,CAAjB;AACA,SAAKmB,WAAL,GAAmBlB,KAAK,CAACa,MAAN,CAAarB,oBAAb,EAAmC,EAAnC,CAAnB,CA5C+F,CA8C/F;;AACA,SAAK2B,WAAL,GAAmB,EAAnB;;AACA,UAAMC,eAAe,GAAG1C,CAAC,IAAIA,CAAC,CAACQ,IAAF,CAAOmC,OAAP,CAAeC,CAAC,IAAK,KAAKH,WAAL,CAAiBG,CAAjB,IAAsB5C,CAAC,CAACC,IAA7C,CAA7B;;AACAoB,IAAAA,OAAO,CAACsB,OAAR,CAAgBD,eAAhB,EAjD+F,CAmD/F;;AACA,SAAKG,OAAL,GAAexB,OAAO,CAACyB,MAAvB,CApD+F,CAsD/F;;AACA,UAAMC,OAAO,GAAGrC,IAAI,CAACC,GAAL,CAASC,KAAK,GAAGA,KAAK,CAACC,IAAT,GAAgB,CAA9B,EAAiC,KAAKS,KAAL,CAAWa,MAAX,CAAkB1B,mBAAlB,EAAuC,CAAvC,CAAjC,CAAhB,CAvD+F,CAwD/F;AACA;AACA;;AACA,SAAKuC,MAAL,GAAc,IAAI7D,KAAJ,CAAU,KAAK8C,SAAL,CAAegB,SAAzB,EAAoCF,OAApC,CAAd;AAEA,SAAKG,eAAL,GAAuB1B,WAAW,IAAI,EAAtC;AACD;AAED;;;;;;AAIA,MAAI2B,EAAJ,GAAU;AACR,WAAO,KAAKpB,GAAZ;AACD;AAED;;;;;;AAIA,MAAInB,KAAJ,GAAa;AACX,WAAO,KAAKoC,MAAZ;AACD;AAED;;;;;;AAIA,MAAIF,MAAJ,GAAc;AACZ,WAAO,KAAKD,OAAZ;AACD;AAED;;;;;;AAIA,MAAIP,MAAJ,GAAc;AACZ,WAAOD,MAAM,CAACC,MAAP,CAAc,KAAKc,QAAL,CAAc,KAAK9B,KAAnB,CAAd,EAAyC+B,OAAzC,EAAP;AACD;AAED;;;;;;AAIA,MAAI/B,KAAJ,GAAa;AACX,WAAOe,MAAM,CAACC,MAAP,CAAc,KAAKE,WAAnB,EAAgCc,IAAhC,CAAqC,KAAKzB,OAA1C,EAAmDwB,OAAnD,EAAP;AACD;AAED;;;;;;;AAKA,MAAIE,KAAJ,GAAa;AACX,WAAOxC,GAAG,CAACyC,SAAJ,CAAc,KAAKlB,MAAnB,CAAP;AACD;AAED;;;;;;;AAKA,MAAImB,UAAJ,GAAkB;AAChB,WAAO1C,GAAG,CAAC2C,cAAJ,CAAmB,KAAKpB,MAAxB,CAAP;AACD;AAED;;;;;;AAIAqB,EAAAA,WAAW,CAAEzC,QAAF,EAAY;AACrB,SAAKe,SAAL,GAAiBf,QAAjB,CADqB,CAErB;;AACA,UAAML,IAAI,GAAGH,IAAI,CAACC,GAAL,CAAS,KAAKC,KAAL,CAAWC,IAApB,EAA0B,KAAKS,KAAL,CAAWa,MAAX,CAAkB1B,mBAAlB,EAAuC,CAAvC,CAA1B,CAAb;AACA,SAAKuC,MAAL,GAAc,IAAI7D,KAAJ,CAAU,KAAK8C,SAAL,CAAegB,SAAzB,EAAoCpC,IAApC,CAAd;AACD;AAED;;;;;;;AAKA+C,EAAAA,GAAG,CAAE3D,IAAF,EAAQ;AACT,WAAO,KAAKmC,WAAL,CAAiBwB,GAAjB,CAAqB3D,IAArB,CAAP;AACD;AAED;;;;;;;AAKA4D,EAAAA,GAAG,CAAEtD,KAAF,EAAS;AACV,WAAO,KAAK6B,WAAL,CAAiBwB,GAAjB,CAAqBrD,KAAK,CAACN,IAAN,IAAcM,KAAnC,MAA8CuD,SAArD;AACD;;AAEDV,EAAAA,QAAQ,CAAEW,WAAF,EAAeC,MAAM,GAAG,CAAC,CAAzB,EAA4BC,OAA5B,EAAqC;AAC3C;AACA,QAAIC,KAAK,GAAGH,WAAW,CAACT,IAAZ,CAAiB,KAAKzB,OAAtB,EAA+BwB,OAA/B,EAAZ,CAF2C,CAI3C;;AACA,QAAIc,SAAS,GAAG,EAAhB,CAL2C,CAM3C;;AACA,QAAIC,MAAM,GAAG,EAAb;AACA,QAAIC,KAAK,GAAG,CAAZ,CAR2C,CAS3C;;AACA,UAAMC,QAAQ,GAAGtE,CAAC,IAAI,KAAK4D,GAAL,CAAS5D,CAAT,CAAtB,CAV2C,CAY3C;;;AACA,UAAMuE,UAAU,GAAGhE,KAAK,IAAI;AAC1B;AACA,UAAI,CAACA,KAAD,IAAU4D,SAAS,CAAC5D,KAAK,CAACN,IAAP,CAAvB,EAAqC;AACnC;AACD,OAJyB,CAM1B;;;AACAiE,MAAAA,KAAK,GAAG,CAAC3D,KAAD,EAAQ,GAAG2D,KAAX,EACLZ,IADK,CACA,KAAKzB,OADL,EAELwB,OAFK,EAAR,CAP0B,CAU1B;;AACAc,MAAAA,SAAS,CAAC5D,KAAK,CAACN,IAAP,CAAT,GAAwB,IAAxB;AACD,KAZD;;AAcA,UAAMuE,QAAQ,GAAGC,SAAS,IAAI;AAC5BL,MAAAA,MAAM,CAACK,SAAS,CAACxE,IAAX,CAAN,GAAyBwE,SAAzB;AACAN,MAAAA,SAAS,CAACM,SAAS,CAACxE,IAAX,CAAT,GAA4B,IAA5B;AACAoE,MAAAA,KAAK;AACN,KAJD,CA3B2C,CAiC3C;AACA;AACA;AACA;;;AACA,WAAOH,KAAK,CAACpB,MAAN,GAAe,CAAf,KAAqBuB,KAAK,GAAGL,MAAR,IAAkBA,MAAM,GAAG,CAAhD,CAAP,EAA2D;AAAE;AAC3D;AACA,YAAMzD,KAAK,GAAG2D,KAAK,CAACQ,KAAN,EAAd,CAFyD,CAGzD;;AACAF,MAAAA,QAAQ,CAACjE,KAAD,CAAR,CAJyD,CAKzD;;AACA,UAAI0D,OAAO,IAAIA,OAAO,KAAK1D,KAAK,CAACN,IAAjC,EAAuC,MANkB,CAQzD;;AACA,YAAMoB,OAAO,GAAGd,KAAK,CAACC,IAAN,CAAWmE,GAAX,CAAeL,QAAf,CAAhB;AACA,YAAMM,OAAO,GAAGvD,OAAO,CAACwD,MAAR,CAAerF,SAAf,CAAhB;AACAoF,MAAAA,OAAO,CAACjC,OAAR,CAAgB4B,UAAhB;AACD;;AAEDL,IAAAA,KAAK,GAAG,EAAR;AACAC,IAAAA,SAAS,GAAG,EAAZ,CApD2C,CAqD3C;;AACA,WAAOC,MAAP;AACD;AAED;;;;;;;AAKA,QAAMU,MAAN,CAAcC,IAAd,EAAoBC,YAAY,GAAG,CAAnC,EAAsCC,GAAG,GAAG,KAA5C,EAAmD;AACjD;AACA,UAAMC,OAAO,GAAGxE,IAAI,CAACC,GAAL,CAAS,KAAKC,KAAL,CAAWC,IAApB,EAA0B,KAAKS,KAAL,CAAWa,MAAX,CAAkB1B,mBAAlB,EAAuC,CAAvC,CAA1B,IAAuE,CAAvF;AACA,SAAKuC,MAAL,GAAc,IAAI7D,KAAJ,CAAU,KAAKyB,KAAL,CAAWuC,EAArB,EAAyB+B,OAAzB,CAAd;AAEA,UAAMC,GAAG,GAAG9C,MAAM,CAACC,MAAP,CAAc,KAAKc,QAAL,CAAc,KAAK9B,KAAnB,EAA0BZ,IAAI,CAACC,GAAL,CAASqE,YAAT,EAAuB,KAAK1D,KAAL,CAAWwB,MAAlC,CAA1B,CAAd,CAAZ,CALiD,CAOjD;AACA;AACA;AACA;;AACA,UAAMsC,YAAY,GAAIC,WAAD,IAAiB;AACpC,UAAIhE,OAAO,GAAG,IAAIiE,GAAJ,EAAd;;AACA,WAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,IAAIF,WAArB,EAAkCE,CAAC,IAAI,CAAvC,EAA0C;AACxC,cAAMC,KAAK,GAAG9E,IAAI,CAAC+E,GAAL,CAASF,CAAC,GAAG,CAAb,EAAgBJ,GAAG,CAACrC,MAAJ,GAAa,CAA7B,CAAd;AACAzB,QAAAA,OAAO,CAACqE,GAAR,CAAYP,GAAG,CAACK,KAAD,CAAf;AACD;;AACD,aAAOnE,OAAP;AACD,KAPD;;AAQA,UAAMsE,UAAU,GAAGP,YAAY,CAAC1E,IAAI,CAAC+E,GAAL,CAAST,YAAT,EAAuBG,GAAG,CAACrC,MAA3B,CAAD,CAA/B,CAnBiD,CAqBjD;;AACA,QAAIqC,GAAG,CAACrC,MAAJ,GAAakC,YAAb,IAA6BG,GAAG,CAACA,GAAG,CAACrC,MAAJ,GAAa,CAAd,CAApC,EAAsD;AACpD6C,MAAAA,UAAU,CAACD,GAAX,CAAeP,GAAG,CAACA,GAAG,CAACrC,MAAJ,GAAa,CAAd,CAAlB;AACD,KAxBgD,CA0BjD;;;AACA,UAAM8C,KAAK,GAAGvD,MAAM,CAACwD,IAAP,CAAY,KAAKvE,KAAL,CAAW+B,OAAX,GAAqBlB,MAArB,CAA4BrB,oBAA5B,EAAkD,EAAlD,CAAZ,CAAd;;AACA,UAAMgF,MAAM,GAAG9F,CAAC,IAAI,CAAC4F,KAAK,CAACG,QAAN,CAAe/F,CAAf,CAArB,CA5BiD,CA6BjD;;;AACA,UAAMgG,IAAI,GAAGrE,KAAK,CAACsE,IAAN,CAAWN,UAAX,EAAuBhB,GAAvB,CAA2B5E,OAA3B,EAAoC8E,MAApC,CAA2CiB,MAA3C,CAAb,CA9BiD,CAgCjD;AACA;;AACA,UAAMvF,KAAK,GAAG,MAAMvB,KAAK,CAACkH,MAAN,CAClB,KAAKpE,QADa,EAElB,KAAKG,SAFa,EAGlB,KAAKkB,EAHa,EAIlB4B,IAJkB,EAKlBa,KALkB,EAMlB,KAAKhF,KANa,EAOlBoF,IAPkB,EAQlBf,GARkB,CAApB;AAWA,UAAMkB,SAAS,GAAG,MAAM,KAAKnE,OAAL,CAAamE,SAAb,CAAuB5F,KAAvB,EAA8B,KAAK0B,SAAL,CAAemE,QAA7C,CAAxB;;AACA,QAAI,CAACD,SAAL,EAAgB;AACd,YAAM,IAAIzE,KAAJ,CAAW,gCAA+B,KAAKO,SAAL,CAAekB,EAAG,sCAA5D,CAAN;AACD;;AAED,SAAKf,WAAL,CAAiBiE,GAAjB,CAAqB9F,KAAK,CAACN,IAA3B,EAAiCM,KAAjC;;AACAqF,IAAAA,KAAK,CAACjD,OAAN,CAAc3C,CAAC,IAAK,KAAKyC,WAAL,CAAiBzC,CAAjB,IAAsBO,KAAK,CAACN,IAAhD;AACA,SAAKuC,WAAL,GAAmB,EAAnB;AACA,SAAKA,WAAL,CAAiBjC,KAAK,CAACN,IAAvB,IAA+BM,KAA/B,CArDiD,CAsDjD;;AACA,SAAKsC,OAAL;AACA,WAAOtC,KAAP;AACD;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA8BA+F,EAAAA,QAAQ,CAAE;AAAEC,IAAAA,EAAE,GAAGzC,SAAP;AAAkB0C,IAAAA,GAAG,GAAG1C,SAAxB;AAAmC2C,IAAAA,EAAE,GAAG3C,SAAxC;AAAmD4C,IAAAA,GAAG,GAAG5C,SAAzD;AAAoEE,IAAAA,MAAM,GAAG,CAAC;AAA9E,MACV,EADQ,EACJ;AACF,QAAIA,MAAM,KAAK,CAAf,EAAkB,OAAQ,aAAc,CAAE,CAAjB,EAAP;AAClB,QAAI,OAAO0C,GAAP,KAAe,QAAnB,EAA6BA,GAAG,GAAG,CAAC,KAAK9C,GAAL,CAAS8C,GAAT,CAAD,CAAN;AAC7B,QAAI,OAAOD,EAAP,KAAc,QAAlB,EAA4BA,EAAE,GAAG,CAAC,KAAK7C,GAAL,CAAS,KAAKA,GAAL,CAAS6C,EAAT,EAAajG,IAAtB,CAAD,CAAL;AAE5B,QAAIkG,GAAG,IAAI,CAAC/E,KAAK,CAACC,OAAN,CAAc8E,GAAd,CAAZ,EAAgC,MAAMxH,QAAQ,CAACyH,0BAAT,EAAN;AAChC,QAAIF,EAAE,IAAI,CAAC9E,KAAK,CAACC,OAAN,CAAc6E,EAAd,CAAX,EAA8B,MAAMvH,QAAQ,CAACyH,0BAAT,EAAN;AAE9B,QAAIC,KAAK,GAAG,CAACF,GAAG,IAAKD,EAAE,IAAI,KAAKnF,KAApB,EAA4BuD,MAA5B,CAAmCrF,SAAnC,CAAZ;AACA,QAAIyE,OAAO,GAAGuC,GAAG,GAAG,KAAK5C,GAAL,CAAS4C,GAAT,EAAcvG,IAAjB,GAAwBsG,EAAE,GAAG,KAAK3C,GAAL,CAAS2C,EAAT,EAAatG,IAAhB,GAAuB,IAAlE;AACA,QAAIoE,KAAK,GAAGJ,OAAO,GAAG,CAAC,CAAJ,GAAQD,MAAM,IAAI,CAAC,CAAtC;AAEA,QAAI3C,OAAO,GAAG,KAAK+B,QAAL,CAAcwD,KAAd,EAAqBvC,KAArB,EAA4BJ,OAA5B,CAAd;AACA,QAAI4C,WAAW,GAAGxE,MAAM,CAACC,MAAP,CAAcjB,OAAd,CAAlB,CAbE,CAeF;;AACA,QAAIkF,EAAJ,EAAQM,WAAW,CAACC,GAAZ,GAhBN,CAkBF;;AACA,QAAI,CAACP,EAAE,IAAIC,GAAP,KAAexC,MAAM,GAAG,CAAC,CAA7B,EAAgC;AAC9B6C,MAAAA,WAAW,GAAGA,WAAW,CAACE,KAAZ,CAAkBF,WAAW,CAAC/D,MAAZ,GAAqBkB,MAAvC,EAA+C6C,WAAW,CAAC/D,MAA3D,CAAd;AACD;;AAED,WAAQ,aAAc;AACpB,WAAK,IAAIyC,CAAT,IAAcsB,WAAd,EAA2B;AACzB,cAAMA,WAAW,CAACtB,CAAD,CAAjB;AACD;AACF,KAJM,EAAP;AAKD;AAED;;;;;;;;;;;;;AAWA,QAAMyB,IAAN,CAAYC,GAAZ,EAAiBC,IAAI,GAAG,CAAC,CAAzB,EAA4B;AAC1B,QAAI,CAAC1H,SAAS,CAACyH,GAAD,CAAd,EAAqB,MAAM/H,QAAQ,CAACiI,kBAAT,EAAN;AACrB,QAAI,CAACpG,GAAG,CAACqG,KAAJ,CAAUH,GAAV,CAAL,EAAqB,MAAM/H,QAAQ,CAACmI,YAAT,EAAN;AACrB,QAAI,KAAKlE,EAAL,KAAY8D,GAAG,CAAC9D,EAApB,EAAwB,OAHE,CAK1B;;AACA,UAAMmE,QAAQ,GAAGvG,GAAG,CAACwG,UAAJ,CAAeN,GAAf,EAAoB,IAApB,CAAjB;AAEA,UAAMO,gBAAgB,GAAG,KAAKvF,SAAL,CAAemE,QAAxC,CAR0B,CAS1B;AACA;;AACA,UAAMqB,SAAS,GAAG,MAAOlH,KAAP,IAAiB;AACjC,YAAM4F,SAAS,GAAG,MAAM,KAAKnE,OAAL,CAAamE,SAAb,CAAuB5F,KAAvB,EAA8BiH,gBAA9B,CAAxB;;AACA,UAAI,CAACrB,SAAL,EAAgB;AACd,cAAM,IAAIzE,KAAJ,CAAW,gCAA+BnB,KAAK,CAACW,QAAN,CAAeiC,EAAG,sCAA5D,CAAN;AACD;AACF,KALD,CAX0B,CAkB1B;;;AACA,UAAMuE,MAAM,GAAG,MAAOnH,KAAP,IAAiB;AAC9B,YAAMoH,OAAO,GAAG,MAAM3I,KAAK,CAAC0I,MAAN,CAAaF,gBAAb,EAA+BjH,KAA/B,CAAtB;AACA,YAAM0C,SAAS,GAAG1C,KAAK,CAACW,QAAN,GAAiBX,KAAK,CAACW,QAAN,CAAe+B,SAAhC,GAA4C1C,KAAK,CAACqH,GAApE;AACA,UAAI,CAACD,OAAL,EAAc,MAAM,IAAIjG,KAAJ,CAAW,iCAAgCnB,KAAK,CAACsH,GAAI,gBAAetH,KAAK,CAACN,IAAK,cAAagD,SAAU,GAAtG,CAAN;AACf,KAJD;;AAMA,UAAM6E,aAAa,GAAGzF,MAAM,CAACC,MAAP,CAAcgF,QAAd,CAAtB;AACA,UAAMzI,IAAI,CAACiJ,aAAD,EAAgB,MAAM9H,CAAN,IAAW;AACnC,YAAMyH,SAAS,CAACzH,CAAD,CAAf;AACA,YAAM0H,MAAM,CAAC1H,CAAD,CAAZ;AACD,KAHS,EAGP;AAAEwB,MAAAA,WAAW,EAAE,KAAK0B;AAApB,KAHO,CAAV,CA1B0B,CA+B1B;;AACA,UAAMR,eAAe,GAAG1C,CAAC,IAAI;AAC3B,YAAMO,KAAK,GAAG,KAAKqD,GAAL,CAAS5D,CAAC,CAACC,IAAX,CAAd;AACA,UAAI,CAACM,KAAL,EAAY,KAAKsC,OAAL;AAAe;;AAC3B7C,MAAAA,CAAC,CAACQ,IAAF,CAAOmC,OAAP,CAAeC,CAAC,IAAK,KAAKH,WAAL,CAAiBG,CAAjB,IAAsB5C,CAAC,CAACC,IAA7C;AACD,KAJD;;AAKAoC,IAAAA,MAAM,CAACC,MAAP,CAAcgF,QAAd,EAAwB3E,OAAxB,CAAgCD,eAAhC,EArC0B,CAuC1B;;AACA,SAAKN,WAAL,CAAiBsD,GAAjB,CAAqB4B,QAArB,EAxC0B,CA0C1B;;;AACA,UAAMS,uBAAuB,GAAG/H,CAAC,IAAI,CAACgI,iBAAiB,CAACC,IAAlB,CAAuBrF,CAAC,IAAIA,CAAC,KAAK5C,CAAC,CAACC,IAApC,CAAtC;;AACA,UAAMiI,iBAAiB,GAAGlI,CAAC,IAAI,CAAC,KAAKyC,WAAL,CAAiBzC,CAAC,CAACC,IAAnB,CAAhC;;AACA,UAAM+H,iBAAiB,GAAG3F,MAAM,CAACC,MAAP,CAAcgF,QAAd,EAAwB3C,GAAxB,CAA4BrE,eAA5B,EAA6C6B,MAA7C,CAAoDjC,OAApD,EAA6D,EAA7D,CAA1B;AACA,UAAMiI,WAAW,GAAGpH,GAAG,CAACwB,SAAJ,CAAcF,MAAM,CAACC,MAAP,CAAcD,MAAM,CAAC+F,MAAP,CAAc,EAAd,EAAkB,KAAK5F,WAAvB,EAAoCyE,GAAG,CAACzE,WAAxC,CAAd,CAAd,EACjBqC,MADiB,CACVkD,uBADU,EAEjBlD,MAFiB,CAEVqD,iBAFU,EAGjB/F,MAHiB,CAGVrB,oBAHU,EAGY,EAHZ,CAApB;AAKA,SAAK0B,WAAL,GAAmB2F,WAAnB,CAnD0B,CAqD1B;;AACA,QAAIjB,IAAI,GAAG,CAAC,CAAZ,EAAe;AACb,UAAImB,GAAG,GAAG,KAAK/F,MAAf;AACA+F,MAAAA,GAAG,GAAGA,GAAG,CAACtB,KAAJ,CAAU,CAACG,IAAX,CAAN;AACA,WAAK9E,WAAL,GAAmB,IAAnB;AACA,WAAKA,WAAL,GAAmB,IAAI1C,UAAJ,CAAe2I,GAAG,CAAClG,MAAJ,CAAWrB,oBAAX,EAAiC,EAAjC,CAAf,CAAnB;AACA,WAAK0B,WAAL,GAAmBzB,GAAG,CAACwB,SAAJ,CAAc8F,GAAd,EAAmBlG,MAAnB,CAA0BrB,oBAA1B,EAAgD,EAAhD,CAAnB;AACA,WAAK+B,OAAL,GAAe,KAAKT,WAAL,CAAiBU,MAAhC;AACD,KA7DyB,CA+D1B;;;AACA,UAAMwF,QAAQ,GAAGjG,MAAM,CAACC,MAAP,CAAc,KAAKE,WAAnB,EAAgCL,MAAhC,CAAuC1B,mBAAvC,EAA4D,CAA5D,CAAjB;AACA,SAAKuC,MAAL,GAAc,IAAI7D,KAAJ,CAAU,KAAKyB,KAAL,CAAWuC,EAArB,EAAyBzC,IAAI,CAACC,GAAL,CAAS,KAAKC,KAAL,CAAWC,IAApB,EAA0ByH,QAA1B,CAAzB,CAAd;AACA,WAAO,IAAP;AACD;AAED;;;;;;AAIAC,EAAAA,MAAM,GAAI;AACR,WAAO;AACLpF,MAAAA,EAAE,EAAE,KAAKA,EADJ;AAEL7B,MAAAA,KAAK,EAAE,KAAKA,KAAL,CACJgC,IADI,CACC,KAAKzB,OADN,EACe;AADf,OAEJwB,OAFI,GAEM;AAFN,OAGJsB,GAHI,CAGA5E,OAHA,CAFF,CAKW;;AALX,KAAP;AAOD;AAED;;;;;;AAIAyI,EAAAA,UAAU,GAAI;AACZ,WAAO;AACLrF,MAAAA,EAAE,EAAE,KAAKA,EADJ;AAEL7B,MAAAA,KAAK,EAAE,KAAKA,KAFP;AAGLgB,MAAAA,MAAM,EAAE,KAAKA;AAHR,KAAP;AAKD;AAED;;;;;;AAIAmG,EAAAA,QAAQ,GAAI;AACV,WAAOC,MAAM,CAACzC,IAAP,CAAY0C,IAAI,CAACC,SAAL,CAAe,KAAKL,MAAL,EAAf,CAAZ,CAAP;AACD;AAED;;;;;;;;;;AAQAzI,EAAAA,QAAQ,CAAE+I,aAAF,EAAiB;AACvB,WAAO,KAAKvG,MAAL,CACJyE,KADI,GAEJ1D,OAFI,GAGJsB,GAHI,CAGA,CAAC3E,CAAD,EAAI8I,GAAJ,KAAY;AACf,YAAMC,OAAO,GAAG/J,KAAK,CAACgK,YAAN,CAAmBhJ,CAAnB,EAAsB,KAAKsC,MAA3B,CAAhB;AACA,YAAM2G,GAAG,GAAGF,OAAO,CAACjG,MAApB;AACA,UAAIoG,OAAO,GAAG,IAAIvH,KAAJ,CAAUjB,IAAI,CAACC,GAAL,CAASsI,GAAG,GAAG,CAAf,EAAkB,CAAlB,CAAV,CAAd;AACAC,MAAAA,OAAO,GAAGD,GAAG,GAAG,CAAN,GAAUC,OAAO,CAACC,IAAR,CAAa,IAAb,CAAV,GAA+BD,OAAzC;AACAA,MAAAA,OAAO,GAAGD,GAAG,GAAG,CAAN,GAAUC,OAAO,CAAC7I,MAAR,CAAe,CAAC,IAAD,CAAf,CAAV,GAAmC6I,OAA7C;AACA;;AACA,aAAOA,OAAO,CAAClC,IAAR,CAAa,EAAb,KAAoB6B,aAAa,GAAGA,aAAa,CAAC7I,CAAC,CAACoJ,OAAH,CAAhB,GAA8BpJ,CAAC,CAACoJ,OAAjE,CAAP;AACD,KAXI,EAYJpC,IAZI,CAYC,IAZD,CAAP;AAaD;AAED;;;;;;;AAKA,SAAOI,KAAP,CAAcH,GAAd,EAAmB;AACjB,WAAOA,GAAG,CAAC9D,EAAJ,KAAWW,SAAX,IACLmD,GAAG,CAAC3F,KAAJ,KAAcwC,SADT,IAELmD,GAAG,CAAC7E,WAAJ,KAAoB0B,SAFtB;AAGD;AAED;;;;;;AAIAuF,EAAAA,WAAW,CAAE;AAAEC,IAAAA;AAAF,MAAa,EAAf,EAAmB;AAC5B,WAAOrK,KAAK,CAACoK,WAAN,CAAkB,KAAKvH,QAAvB,EAAiC,IAAjC,EAAuC;AAAEwH,MAAAA;AAAF,KAAvC,CAAP;AACD;AAED;;;;;;;;;;;;;;;AAaA,eAAaC,aAAb,CAA4BtI,IAA5B,EAAkCC,QAAlC,EAA4CjB,IAA5C,EACE;AAAEmB,IAAAA,MAAF;AAAU0B,IAAAA,MAAM,GAAG,CAAC,CAApB;AAAuB0G,IAAAA,OAAO,GAAG,EAAjC;AAAqCC,IAAAA,OAArC;AAA8CjI,IAAAA,WAA9C;AAA2DD,IAAAA,MAA3D;AAAmEmI,IAAAA;AAAnE,MAA0F,EAD5F,EACgG;AAC9F;AACA,UAAM;AAAEvI,MAAAA,KAAF;AAASE,MAAAA,OAAT;AAAkBC,MAAAA;AAAlB,QAA4B,MAAMrC,KAAK,CAACsK,aAAN,CAAoBtI,IAApB,EAA0BhB,IAA1B,EACtC;AAAE6C,MAAAA,MAAF;AAAU0G,MAAAA,OAAV;AAAmBC,MAAAA,OAAnB;AAA4BC,MAAAA,kBAA5B;AAAgDlI,MAAAA,WAAhD;AAA6DD,MAAAA;AAA7D,KADsC,CAAxC;AAEA,WAAO,IAAIR,GAAJ,CAAQE,IAAR,EAAcC,QAAd,EAAwB;AAAEC,MAAAA,KAAF;AAASC,MAAAA,MAAT;AAAiBC,MAAAA,OAAjB;AAA0BC,MAAAA,KAA1B;AAAiCC,MAAAA;AAAjC,KAAxB,CAAP;AACD;AAED;;;;;;;;;;;;;;;;AAcA,eAAaoI,aAAb,CAA4B1I,IAA5B,EAAkCC,QAAlC,EAA4CjB,IAA5C,EACE;AAAEkB,IAAAA,KAAF;AAASC,IAAAA,MAAT;AAAiB0B,IAAAA,MAAM,GAAG,CAAC,CAA3B;AAA8B0G,IAAAA,OAAO,GAAG,EAAxC;AAA4CC,IAAAA,OAA5C;AAAqDjI,IAAAA,WAArD;AAAkED,IAAAA,MAAlE;AAA0EmI,IAAAA;AAA1E,MAAiG,EADnG,EACuG;AACrG;AACA,UAAM;AAAErI,MAAAA;AAAF,QAAc,MAAMpC,KAAK,CAAC0K,aAAN,CAAoB1I,IAApB,EAA0BhB,IAA1B,EACxB;AAAE6C,MAAAA,MAAF;AAAU0G,MAAAA,OAAV;AAAmBC,MAAAA,OAAnB;AAA4BjI,MAAAA,WAA5B;AAAyCkI,MAAAA;AAAzC,KADwB,CAA1B;AAEA,WAAO,IAAI3I,GAAJ,CAAQE,IAAR,EAAcC,QAAd,EAAwB;AAAEC,MAAAA,KAAF;AAASC,MAAAA,MAAT;AAAiBC,MAAAA,OAAjB;AAA0BE,MAAAA;AAA1B,KAAxB,CAAP;AACD;AAED;;;;;;;;;;;;;;AAYA,eAAaqI,QAAb,CAAuB3I,IAAvB,EAA6BC,QAA7B,EAAuC2I,IAAvC,EACE;AAAEzI,IAAAA,MAAF;AAAU0B,IAAAA,MAAM,GAAG,CAAC,CAApB;AAAuB2G,IAAAA,OAAvB;AAAgClI,IAAAA,MAAhC;AAAwCmI,IAAAA;AAAxC,MAA+D,EADjE,EACqE;AACnE;AACA,UAAM;AAAEvI,MAAAA,KAAF;AAASE,MAAAA;AAAT,QAAqB,MAAMpC,KAAK,CAAC2K,QAAN,CAAe3I,IAAf,EAAqB4I,IAArB,EAC/B;AAAE/G,MAAAA,MAAF;AAAU2G,MAAAA,OAAV;AAAmBC,MAAAA;AAAnB,KAD+B,CAAjC;AAEA,WAAO,IAAI3I,GAAJ,CAAQE,IAAR,EAAcC,QAAd,EAAwB;AAAEC,MAAAA,KAAF;AAASC,MAAAA,MAAT;AAAiBC,MAAAA,OAAjB;AAA0BE,MAAAA;AAA1B,KAAxB,CAAP;AACD;AAED;;;;;;;;;;;;;;;AAaA,eAAauI,SAAb,CAAwB7I,IAAxB,EAA8BC,QAA9B,EAAwC6I,aAAxC,EACE;AAAE3I,IAAAA,MAAF;AAAU0B,IAAAA,MAAM,GAAG,CAAC,CAApB;AAAuB0G,IAAAA,OAAO,GAAG,EAAjC;AAAqCC,IAAAA,OAArC;AAA8CjI,IAAAA,WAA9C;AAA2DD,IAAAA,MAA3D;AAAmEmI,IAAAA;AAAnE,MAA0F,EAD5F,EACgG;AAC9F;AACA,UAAM;AAAEvI,MAAAA,KAAF;AAASE,MAAAA;AAAT,QAAqB,MAAMpC,KAAK,CAAC6K,SAAN,CAAgB7I,IAAhB,EAAsB8I,aAAtB,EAC/B;AAAEjH,MAAAA,MAAF;AAAU0G,MAAAA,OAAV;AAAmBC,MAAAA,OAAnB;AAA4BjI,MAAAA,WAA5B;AAAyCkI,MAAAA;AAAzC,KAD+B,CAAjC;AAEA,WAAO,IAAI3I,GAAJ,CAAQE,IAAR,EAAcC,QAAd,EAAwB;AAAEC,MAAAA,KAAF;AAASC,MAAAA,MAAT;AAAiBC,MAAAA,OAAjB;AAA0BE,MAAAA;AAA1B,KAAxB,CAAP;AACD;AAED;;;;;;;;;;;AASA,SAAOgB,SAAP,CAAkBlB,OAAlB,EAA2B;AACzB,QAAI2I,YAAY,GAAG,CAAC7J,GAAD,EAAMI,KAAN,EAAauI,GAAb,EAAkBmB,GAAlB,KAA0B;AAC3C,UAAIC,WAAW,GAAGlK,CAAC,IAAKG,GAAG,CAACH,CAAD,CAAH,GAASO,KAAK,CAACN,IAAvC;;AACAM,MAAAA,KAAK,CAACC,IAAN,CAAWmC,OAAX,CAAmBuH,WAAnB;AACA,aAAO/J,GAAP;AACD,KAJD;;AAMA,QAAIgK,KAAK,GAAG9I,OAAO,CAACc,MAAR,CAAe6H,YAAf,EAA6B,EAA7B,CAAZ;;AAEA,QAAII,MAAM,GAAGpK,CAAC,IAAImK,KAAK,CAACnK,CAAC,CAACC,IAAH,CAAL,KAAkB6D,SAApC;;AACA,QAAIuG,UAAU,GAAG,CAACzH,CAAD,EAAI0H,CAAJ,KAAU1H,CAAC,CAAChC,KAAF,CAAQuC,EAAR,GAAamH,CAAC,CAAC1J,KAAF,CAAQuC,EAAhD;;AAEA,WAAO9B,OAAO,CAACwD,MAAR,CAAeuF,MAAf,EAAuB9G,IAAvB,CAA4B+G,UAA5B,CAAP;AACD,GAlmBoB,CAomBrB;AACA;;;AACA,SAAO7G,SAAP,CAAkBnC,OAAlB,EAA2B;AACzB;AACA,QAAIkJ,YAAY,GAAG,EAAnB,CAFyB,CAGzB;;AACA,QAAIC,SAAS,GAAG,EAAhB,CAJyB,CAKzB;;AACA,QAAIC,MAAM,GAAG,EAAb,CANyB,CAOzB;;AACA,QAAI7E,KAAK,GAAG,EAAZ;;AAEA,QAAI8E,UAAU,GAAI1K,CAAD,IAAO;AACtB,UAAIA,CAAC,CAACQ,IAAF,CAAOsC,MAAP,KAAkB,CAAtB,EAAyB;AACvB0H,QAAAA,SAAS,CAACG,IAAV,CAAe3K,CAAf;AACD;;AACD,UAAI4K,iBAAiB,GAAIhI,CAAD,IAAO;AAC7B;AACA,YAAI,CAAC2H,YAAY,CAAC3H,CAAD,CAAjB,EAAsB2H,YAAY,CAAC3H,CAAD,CAAZ,GAAkB,EAAlB;AACtB2H,QAAAA,YAAY,CAAC3H,CAAD,CAAZ,CAAgB+H,IAAhB,CAAqB3K,CAArB;AACD,OAJD,CAJsB,CAUtB;;;AACAA,MAAAA,CAAC,CAACQ,IAAF,CAAOmC,OAAP,CAAeiI,iBAAf,EAXsB,CAYtB;;AACAhF,MAAAA,KAAK,GAAGA,KAAK,CAACvF,MAAN,CAAaL,CAAC,CAACQ,IAAf,CAAR,CAbsB,CActB;;AACAiK,MAAAA,MAAM,CAACzK,CAAC,CAACC,IAAH,CAAN,GAAiB,IAAjB;AACD,KAhBD,CAVyB,CA4BzB;;;AACAoB,IAAAA,OAAO,CAACsB,OAAR,CAAgB+H,UAAhB;;AAEA,QAAIG,UAAU,GAAG,CAAC1K,GAAD,EAAMkB,OAAN,EAAeyH,GAAf,EAAoBmB,GAApB,KAA4B9J,GAAG,CAACE,MAAJ,CAAWZ,WAAW,CAAC4B,OAAD,EAAU,MAAV,CAAtB,CAA7C;;AACA,QAAI+I,MAAM,GAAGpK,CAAC,IAAIyK,MAAM,CAACzK,CAAD,CAAN,KAAc8D,SAAhC;;AACA,QAAIgH,oBAAoB,GAAG9K,CAAC,IAAIuK,YAAY,CAACvK,CAAD,CAA5C,CAjCyB,CAmCzB;;;AACA,UAAMuD,KAAK,GAAGqC,KAAK,CAAC;AAAD,KAChBf,MADW,CACJuF,MADI,EACI;AADJ,KAEXzF,GAFW,CAEPmG,oBAFO,EAEe;AAFf,KAGX3I,MAHW,CAGJ0I,UAHI,EAGQ,EAHR,EAGY;AAHZ,KAIXxK,MAJW,CAIJmK,SAJI,CAAd,CApCyB,CAwCJ;;AAErB,WAAO/K,WAAW,CAAC8D,KAAD,EAAQ,MAAR,CAAX,CAA2BD,IAA3B,CAAgCtE,KAAK,CAAC+L,OAAtC,CAAP;AACD,GAjpBoB,CAmpBrB;AACA;;;AACA,SAAOrH,cAAP,CAAuBrC,OAAvB,EAAgC;AAC9B,QAAIoJ,MAAM,GAAG,EAAb;;AACA,QAAIC,UAAU,GAAG1K,CAAC,IAAKyK,MAAM,CAACzK,CAAC,CAACC,IAAH,CAAN,GAAiB,IAAxC;;AACA,QAAI+K,gBAAgB,GAAG,CAAC7K,GAAD,EAAMI,KAAN,EAAauI,GAAb,EAAkBmB,GAAlB,KAA0B;AAC/C,UAAIC,WAAW,GAAIlK,CAAD,IAAO;AACvB;AACA,YAAIyK,MAAM,CAACzK,CAAD,CAAN,KAAc8D,SAAlB,EAA6B;AAC3B3D,UAAAA,GAAG,CAAC8K,MAAJ,CAAW,CAAX,EAAc,CAAd,EAAiBjL,CAAjB;AACD;AACF,OALD;;AAMAO,MAAAA,KAAK,CAACC,IAAN,CAAW6C,OAAX,GAAqBV,OAArB,CAA6BuH,WAA7B;AACA,aAAO/J,GAAP;AACD,KATD;;AAWAkB,IAAAA,OAAO,CAACsB,OAAR,CAAgB+H,UAAhB;AACA,WAAOrJ,OAAO,CAACc,MAAR,CAAe6I,gBAAf,EAAiC,EAAjC,CAAP;AACD;;AAED,SAAOzD,UAAP,CAAmB3E,CAAnB,EAAsB0H,CAAtB,EAAyB;AACvB,QAAIpG,KAAK,GAAG7B,MAAM,CAACwD,IAAP,CAAYjD,CAAC,CAACJ,WAAd,CAAZ;AACA,QAAI2B,SAAS,GAAG,EAAhB;AACA,QAAIhE,GAAG,GAAG,EAAV;;AAEA,UAAM+K,WAAW,GAAGjL,IAAI,IAAI;AAC1B,UAAI,CAACkE,SAAS,CAAClE,IAAD,CAAV,IAAoB,CAACqK,CAAC,CAAC1G,GAAF,CAAM3D,IAAN,CAAzB,EAAsC;AACpCiE,QAAAA,KAAK,CAACyG,IAAN,CAAW1K,IAAX;AACAkE,QAAAA,SAAS,CAAClE,IAAD,CAAT,GAAkB,IAAlB;AACD;AACF,KALD;;AAOA,WAAOiE,KAAK,CAACpB,MAAN,GAAe,CAAtB,EAAyB;AACvB,YAAM7C,IAAI,GAAGiE,KAAK,CAACQ,KAAN,EAAb;AACA,YAAMnE,KAAK,GAAGqC,CAAC,CAACgB,GAAF,CAAM3D,IAAN,CAAd;;AACA,UAAIM,KAAK,IAAI,CAAC+J,CAAC,CAAC1G,GAAF,CAAM3D,IAAN,CAAV,IAAyBM,KAAK,CAAC4C,EAAN,KAAamH,CAAC,CAACnH,EAA5C,EAAgD;AAC9ChD,QAAAA,GAAG,CAACI,KAAK,CAACN,IAAP,CAAH,GAAkBM,KAAlB;AACA4D,QAAAA,SAAS,CAAC5D,KAAK,CAACN,IAAP,CAAT,GAAwB,IAAxB;AACAM,QAAAA,KAAK,CAACC,IAAN,CAAWmC,OAAX,CAAmBuI,WAAnB;AACD;AACF;;AACD,WAAO/K,GAAP;AACD;;AA7rBoB;;AAgsBvBgL,MAAM,CAACC,OAAP,GAAiBrK,GAAjB;AACAoK,MAAM,CAACC,OAAP,CAAehM,OAAf,GAAyBA,OAAzB;AACA+L,MAAM,CAACC,OAAP,CAAepM,KAAf,GAAuBA,KAAvB;AACAmM,MAAM,CAACC,OAAP,CAAe7L,gBAAf,GAAkCA,gBAAlC","sourcesContent":["'use strict'\n\nconst pMap = require('p-map')\nconst GSet = require('./g-set')\nconst Entry = require('./entry')\nconst LogIO = require('./log-io')\nconst LogError = require('./log-errors')\nconst Clock = require('./lamport-clock')\nconst Sorting = require('./log-sorting')\nconst { LastWriteWins, NoZeroes } = Sorting\nconst AccessController = require('./default-access-controller')\nconst { isDefined, findUniques } = require('./utils')\nconst EntryIndex = require('./entry-index')\nconst randomId = () => new Date().getTime().toString()\nconst getHash = e => e.hash\nconst flatMap = (res, acc) => res.concat(acc)\nconst getNextPointers = entry => entry.next\nconst maxClockTimeReducer = (res, acc) => Math.max(res, acc.clock.time)\nconst uniqueEntriesReducer = (res, acc) => {\n  res[acc.hash] = acc\n  return res\n}\n\n/**\n * Log.\n *\n * @description\n * Log implements a G-Set CRDT and adds ordering.\n *\n * From:\n * \"A comprehensive study of Convergent and Commutative Replicated Data Types\"\n * https://hal.inria.fr/inria-00555588\n */\nclass Log extends GSet {\n  /**\n   * Create a new Log instance\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {Object} identity Identity (https://github.com/orbitdb/orbit-db-identity-provider/blob/master/src/identity.js)\n   * @param {Object} options\n   * @param {string} options.logId ID of the log\n   * @param {Object} options.access AccessController (./default-access-controller)\n   * @param {Array<Entry>} options.entries An Array of Entries from which to create the log\n   * @param {Array<Entry>} options.heads Set the heads of the log\n   * @param {Clock} options.clock Set the clock of the log\n   * @param {Function} options.sortFn The sort function - by default LastWriteWins\n   * @return {Log} The log instance\n   */\n  constructor (ipfs, identity, { logId, access, entries, heads, clock, sortFn, concurrency } = {}) {\n    if (!isDefined(ipfs)) {\n      throw LogError.IPFSNotDefinedError()\n    }\n\n    if (!isDefined(identity)) {\n      throw new Error('Identity is required')\n    }\n\n    if (!isDefined(access)) {\n      access = new AccessController()\n    }\n\n    if (isDefined(entries) && !Array.isArray(entries)) {\n      throw new Error(`'entries' argument must be an array of Entry instances`)\n    }\n\n    if (isDefined(heads) && !Array.isArray(heads)) {\n      throw new Error(`'heads' argument must be an array`)\n    }\n\n    if (!isDefined(sortFn)) {\n      sortFn = LastWriteWins\n    }\n\n    super()\n\n    this._sortFn = NoZeroes(sortFn)\n\n    this._storage = ipfs\n    this._id = logId || randomId()\n\n    // Access Controller\n    this._access = access\n    // Identity\n    this._identity = identity\n\n    // Add entries to the internal cache\n    const uniqueEntries = (entries || []).reduce(uniqueEntriesReducer, {})\n    this._entryIndex = new EntryIndex(uniqueEntries)\n    entries = Object.values(uniqueEntries) || []\n\n    // Set heads if not passed as an argument\n    heads = heads || Log.findHeads(entries)\n    this._headsIndex = heads.reduce(uniqueEntriesReducer, {})\n\n    // Index of all next pointers in this log\n    this._nextsIndex = {}\n    const addToNextsIndex = e => e.next.forEach(a => (this._nextsIndex[a] = e.hash))\n    entries.forEach(addToNextsIndex)\n\n    // Set the length, we calculate the length manually internally\n    this._length = entries.length\n\n    // Set the clock\n    const maxTime = Math.max(clock ? clock.time : 0, this.heads.reduce(maxClockTimeReducer, 0))\n    // Take the given key as the clock id is it's a Key instance,\n    // otherwise if key was given, take whatever it is,\n    // and if it was null, take the given id as the clock id\n    this._clock = new Clock(this._identity.publicKey, maxTime)\n\n    this.joinConcurrency = concurrency || 16\n  }\n\n  /**\n   * Returns the ID of the log.\n   * @returns {string}\n   */\n  get id () {\n    return this._id\n  }\n\n  /**\n   * Returns the clock of the log.\n   * @returns {string}\n   */\n  get clock () {\n    return this._clock\n  }\n\n  /**\n   * Returns the length of the log.\n   * @return {number} Length\n   */\n  get length () {\n    return this._length\n  }\n\n  /**\n   * Returns the values in the log.\n   * @returns {Array<Entry>}\n   */\n  get values () {\n    return Object.values(this.traverse(this.heads)).reverse()\n  }\n\n  /**\n   * Returns an array of heads as hashes.\n   * @returns {Array<string>}\n   */\n  get heads () {\n    return Object.values(this._headsIndex).sort(this._sortFn).reverse()\n  }\n\n  /**\n   * Returns an array of Entry objects that reference entries which\n   * are not in the log currently.\n   * @returns {Array<Entry>}\n   */\n  get tails () {\n    return Log.findTails(this.values)\n  }\n\n  /**\n   * Returns an array of hashes that are referenced by entries which\n   * are not in the log currently.\n   * @returns {Array<string>} Array of hashes\n   */\n  get tailHashes () {\n    return Log.findTailHashes(this.values)\n  }\n\n  /**\n   * Set the identity for the log\n   * @param {Identity} [identity] The identity to be set\n   */\n  setIdentity (identity) {\n    this._identity = identity\n    // Find the latest clock from the heads\n    const time = Math.max(this.clock.time, this.heads.reduce(maxClockTimeReducer, 0))\n    this._clock = new Clock(this._identity.publicKey, time)\n  }\n\n  /**\n   * Find an entry.\n   * @param {string} [hash] The hashes of the entry\n   * @returns {Entry|undefined}\n   */\n  get (hash) {\n    return this._entryIndex.get(hash)\n  }\n\n  /**\n   * Checks if a entry is part of the log\n   * @param {string} hash The hash of the entry\n   * @returns {boolean}\n   */\n  has (entry) {\n    return this._entryIndex.get(entry.hash || entry) !== undefined\n  }\n\n  traverse (rootEntries, amount = -1, endHash) {\n    // Sort the given given root entries and use as the starting stack\n    let stack = rootEntries.sort(this._sortFn).reverse()\n\n    // Cache for checking if we've processed an entry already\n    let traversed = {}\n    // End result\n    let result = {}\n    let count = 0\n    // Named function for getting an entry from the log\n    const getEntry = e => this.get(e)\n\n    // Add an entry to the stack and traversed nodes index\n    const addToStack = entry => {\n      // If we've already processed the entry, don't add it to the stack\n      if (!entry || traversed[entry.hash]) {\n        return\n      }\n\n      // Add the entry in front of the stack and sort\n      stack = [entry, ...stack]\n        .sort(this._sortFn)\n        .reverse()\n      // Add to the cache of processed entries\n      traversed[entry.hash] = true\n    }\n\n    const addEntry = rootEntry => {\n      result[rootEntry.hash] = rootEntry\n      traversed[rootEntry.hash] = true\n      count++\n    }\n\n    // Start traversal\n    // Process stack until it's empty (traversed the full log)\n    // or when we have the requested amount of entries\n    // If requested entry amount is -1, traverse all\n    while (stack.length > 0 && (count < amount || amount < 0)) { // eslint-disable-line no-unmodified-loop-condition\n      // Get the next element from the stack\n      const entry = stack.shift()\n      // Add to the result\n      addEntry(entry)\n      // If it is the specified end hash, break out of the while loop\n      if (endHash && endHash === entry.hash) break\n\n      // Add entry's next references to the stack\n      const entries = entry.next.map(getEntry)\n      const defined = entries.filter(isDefined)\n      defined.forEach(addToStack)\n    }\n\n    stack = []\n    traversed = {}\n    // End result\n    return result\n  }\n\n  /**\n   * Append an entry to the log.\n   * @param {Entry} entry Entry to add\n   * @return {Log} New Log containing the appended value\n   */\n  async append (data, pointerCount = 1, pin = false) {\n    // Update the clock (find the latest clock)\n    const newTime = Math.max(this.clock.time, this.heads.reduce(maxClockTimeReducer, 0)) + 1\n    this._clock = new Clock(this.clock.id, newTime)\n\n    const all = Object.values(this.traverse(this.heads, Math.max(pointerCount, this.heads.length)))\n\n    // If pointer count is 4, returns 2\n    // If pointer count is 8, returns 3 references\n    // If pointer count is 512, returns 9 references\n    // If pointer count is 2048, returns 11 references\n    const getEveryPow2 = (maxDistance) => {\n      let entries = new Set()\n      for (let i = 1; i <= maxDistance; i *= 2) {\n        const index = Math.min(i - 1, all.length - 1)\n        entries.add(all[index])\n      }\n      return entries\n    }\n    const references = getEveryPow2(Math.min(pointerCount, all.length))\n\n    // Always include the last known reference\n    if (all.length < pointerCount && all[all.length - 1]) {\n      references.add(all[all.length - 1])\n    }\n\n    // Create the next pointers from heads\n    const nexts = Object.keys(this.heads.reverse().reduce(uniqueEntriesReducer, {}))\n    const isNext = e => !nexts.includes(e)\n    // Delete the heads from the refs\n    const refs = Array.from(references).map(getHash).filter(isNext)\n\n    // @TODO: Split Entry.create into creating object, checking permission, signing and then posting to IPFS\n    // Create the entry and add it to the internal cache\n    const entry = await Entry.create(\n      this._storage,\n      this._identity,\n      this.id,\n      data,\n      nexts,\n      this.clock,\n      refs,\n      pin\n    )\n\n    const canAppend = await this._access.canAppend(entry, this._identity.provider)\n    if (!canAppend) {\n      throw new Error(`Could not append entry, key \"${this._identity.id}\" is not allowed to write to the log`)\n    }\n\n    this._entryIndex.set(entry.hash, entry)\n    nexts.forEach(e => (this._nextsIndex[e] = entry.hash))\n    this._headsIndex = {}\n    this._headsIndex[entry.hash] = entry\n    // Update the length\n    this._length++\n    return entry\n  }\n\n  /*\n   * Creates a javscript iterator over log entries\n   *\n   * @param {Object} options\n   * @param {string|Array} options.gt Beginning hash of the iterator, non-inclusive\n   * @param {string|Array} options.gte Beginning hash of the iterator, inclusive\n   * @param {string|Array} options.lt Ending hash of the iterator, non-inclusive\n   * @param {string|Array} options.lte Ending hash of the iterator, inclusive\n   * @param {amount} options.amount Number of entried to return to / from the gte / lte hash\n   * @returns {Symbol.Iterator} Iterator object containing log entries\n   *\n   * @examples\n   *\n   * (async () => {\n   *   log1 = new Log(ipfs, testIdentity, { logId: 'X' })\n   *\n   *   for (let i = 0; i <= 100; i++) {\n   *     await log1.append('entry' + i)\n   *   }\n   *\n   *   let it = log1.iterator({\n   *     lte: 'zdpuApFd5XAPkCTmSx7qWQmQzvtdJPtx2K5p9to6ytCS79bfk',\n   *     amount: 10\n   *   })\n   *\n   *   [...it].length // 10\n   * })()\n   *\n   *\n   */\n  iterator ({ gt = undefined, gte = undefined, lt = undefined, lte = undefined, amount = -1 } =\n  {}) {\n    if (amount === 0) return (function * () {})()\n    if (typeof lte === 'string') lte = [this.get(lte)]\n    if (typeof lt === 'string') lt = [this.get(this.get(lt).next)]\n\n    if (lte && !Array.isArray(lte)) throw LogError.LtOrLteMustBeStringOrArray()\n    if (lt && !Array.isArray(lt)) throw LogError.LtOrLteMustBeStringOrArray()\n\n    let start = (lte || (lt || this.heads)).filter(isDefined)\n    let endHash = gte ? this.get(gte).hash : gt ? this.get(gt).hash : null\n    let count = endHash ? -1 : amount || -1\n\n    let entries = this.traverse(start, count, endHash)\n    let entryValues = Object.values(entries)\n\n    // Strip off last entry if gt is non-inclusive\n    if (gt) entryValues.pop()\n\n    // Deal with the amount argument working backwards from gt/gte\n    if ((gt || gte) && amount > -1) {\n      entryValues = entryValues.slice(entryValues.length - amount, entryValues.length)\n    }\n\n    return (function * () {\n      for (let i in entryValues) {\n        yield entryValues[i]\n      }\n    })()\n  }\n\n  /**\n   * Join two logs.\n   *\n   * Joins another log into this one.\n   *\n   * @param {Log} log Log to join with this Log\n   * @param {number} [size=-1] Max size of the joined log\n   * @returns {Promise<Log>} This Log instance\n   * @example\n   * await log1.join(log2)\n   */\n  async join (log, size = -1) {\n    if (!isDefined(log)) throw LogError.LogNotDefinedError()\n    if (!Log.isLog(log)) throw LogError.NotALogError()\n    if (this.id !== log.id) return\n\n    // Get the difference of the logs\n    const newItems = Log.difference(log, this)\n\n    const identityProvider = this._identity.provider\n    // Verify if entries are allowed to be added to the log and throws if\n    // there's an invalid entry\n    const permitted = async (entry) => {\n      const canAppend = await this._access.canAppend(entry, identityProvider)\n      if (!canAppend) {\n        throw new Error(`Could not append entry, key \"${entry.identity.id}\" is not allowed to write to the log`)\n      }\n    }\n\n    // Verify signature for each entry and throws if there's an invalid signature\n    const verify = async (entry) => {\n      const isValid = await Entry.verify(identityProvider, entry)\n      const publicKey = entry.identity ? entry.identity.publicKey : entry.key\n      if (!isValid) throw new Error(`Could not validate signature \"${entry.sig}\" for entry \"${entry.hash}\" and key \"${publicKey}\"`)\n    }\n\n    const entriesToJoin = Object.values(newItems)\n    await pMap(entriesToJoin, async e => {\n      await permitted(e)\n      await verify(e)\n    }, { concurrency: this.joinConcurrency })\n\n    // Update the internal next pointers index\n    const addToNextsIndex = e => {\n      const entry = this.get(e.hash)\n      if (!entry) this._length++ /* istanbul ignore else */\n      e.next.forEach(a => (this._nextsIndex[a] = e.hash))\n    }\n    Object.values(newItems).forEach(addToNextsIndex)\n\n    // Update the internal entry index\n    this._entryIndex.add(newItems)\n\n    // Merge the heads\n    const notReferencedByNewItems = e => !nextsFromNewItems.find(a => a === e.hash)\n    const notInCurrentNexts = e => !this._nextsIndex[e.hash]\n    const nextsFromNewItems = Object.values(newItems).map(getNextPointers).reduce(flatMap, [])\n    const mergedHeads = Log.findHeads(Object.values(Object.assign({}, this._headsIndex, log._headsIndex)))\n      .filter(notReferencedByNewItems)\n      .filter(notInCurrentNexts)\n      .reduce(uniqueEntriesReducer, {})\n\n    this._headsIndex = mergedHeads\n\n    // Slice to the requested size\n    if (size > -1) {\n      let tmp = this.values\n      tmp = tmp.slice(-size)\n      this._entryIndex = null\n      this._entryIndex = new EntryIndex(tmp.reduce(uniqueEntriesReducer, {}))\n      this._headsIndex = Log.findHeads(tmp).reduce(uniqueEntriesReducer, {})\n      this._length = this._entryIndex.length\n    }\n\n    // Find the latest clock from the heads\n    const maxClock = Object.values(this._headsIndex).reduce(maxClockTimeReducer, 0)\n    this._clock = new Clock(this.clock.id, Math.max(this.clock.time, maxClock))\n    return this\n  }\n\n  /**\n   * Get the log in JSON format.\n   * @returns {Object} An object with the id and heads properties\n   */\n  toJSON () {\n    return {\n      id: this.id,\n      heads: this.heads\n        .sort(this._sortFn) // default sorting\n        .reverse() // we want the latest as the first element\n        .map(getHash) // return only the head hashes\n    }\n  }\n\n  /**\n   * Get the log in JSON format as a snapshot.\n   * @returns {Object} An object with the id, heads and value properties\n   */\n  toSnapshot () {\n    return {\n      id: this.id,\n      heads: this.heads,\n      values: this.values\n    }\n  }\n\n  /**\n   * Get the log as a Buffer.\n   * @returns {Buffer}\n   */\n  toBuffer () {\n    return Buffer.from(JSON.stringify(this.toJSON()))\n  }\n\n  /**\n   * Returns the log entries as a formatted string.\n   * @returns {string}\n   * @example\n   * two\n   * └─one\n   *   └─three\n   */\n  toString (payloadMapper) {\n    return this.values\n      .slice()\n      .reverse()\n      .map((e, idx) => {\n        const parents = Entry.findChildren(e, this.values)\n        const len = parents.length\n        let padding = new Array(Math.max(len - 1, 0))\n        padding = len > 1 ? padding.fill('  ') : padding\n        padding = len > 0 ? padding.concat(['└─']) : padding\n        /* istanbul ignore next */\n        return padding.join('') + (payloadMapper ? payloadMapper(e.payload) : e.payload)\n      })\n      .join('\\n')\n  }\n\n  /**\n   * Check whether an object is a Log instance.\n   * @param {Object} log An object to check\n   * @returns {boolean}\n   */\n  static isLog (log) {\n    return log.id !== undefined &&\n      log.heads !== undefined &&\n      log._entryIndex !== undefined\n  }\n\n  /**\n   * Get the log's multihash.\n   * @returns {Promise<string>} Multihash of the Log as Base58 encoded string.\n   */\n  toMultihash ({ format } = {}) {\n    return LogIO.toMultihash(this._storage, this, { format })\n  }\n\n  /**\n   * Create a log from a hashes.\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {Identity} identity The identity instance\n   * @param {string} hash The log hash\n   * @param {Object} options\n   * @param {AccessController} options.access The access controller instance\n   * @param {number} options.length How many items to include in the log\n   * @param {Array<Entry>} options.exclude Entries to not fetch (cached)\n   * @param {function(hash, entry, parent, depth)} options.onProgressCallback\n   * @param {Function} options.sortFn The sort function - by default LastWriteWins\n   * @returns {Promise<Log>}\n   */\n  static async fromMultihash (ipfs, identity, hash,\n    { access, length = -1, exclude = [], timeout, concurrency, sortFn, onProgressCallback } = {}) {\n    // TODO: need to verify the entries with 'key'\n    const { logId, entries, heads } = await LogIO.fromMultihash(ipfs, hash,\n      { length, exclude, timeout, onProgressCallback, concurrency, sortFn })\n    return new Log(ipfs, identity, { logId, access, entries, heads, sortFn })\n  }\n\n  /**\n   * Create a log from a single entry's hash.\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {Identity} identity The identity instance\n   * @param {string} hash The entry's hash\n   * @param {Object} options\n   * @param {string} options.logId The ID of the log\n   * @param {AccessController} options.access The access controller instance\n   * @param {number} options.length How many entries to include in the log\n   * @param {Array<Entry>} options.exclude Entries to not fetch (cached)\n   * @param {function(hash, entry, parent, depth)} options.onProgressCallback\n   * @param {Function} options.sortFn The sort function - by default LastWriteWins\n   * @return {Promise<Log>} New Log\n   */\n  static async fromEntryHash (ipfs, identity, hash,\n    { logId, access, length = -1, exclude = [], timeout, concurrency, sortFn, onProgressCallback } = {}) {\n    // TODO: need to verify the entries with 'key'\n    const { entries } = await LogIO.fromEntryHash(ipfs, hash,\n      { length, exclude, timeout, concurrency, onProgressCallback })\n    return new Log(ipfs, identity, { logId, access, entries, sortFn })\n  }\n\n  /**\n   * Create a log from a Log Snapshot JSON.\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {Identity} identity The identity instance\n   * @param {Object} json Log snapshot as JSON object\n   * @param {Object} options\n   * @param {AccessController} options.access The access controller instance\n   * @param {number} options.length How many entries to include in the log\n   * @param {function(hash, entry, parent, depth)} [options.onProgressCallback]\n   * @param {Function} options.sortFn The sort function - by default LastWriteWins\n   * @return {Promise<Log>} New Log\n   */\n  static async fromJSON (ipfs, identity, json,\n    { access, length = -1, timeout, sortFn, onProgressCallback } = {}) {\n    // TODO: need to verify the entries with 'key'\n    const { logId, entries } = await LogIO.fromJSON(ipfs, json,\n      { length, timeout, onProgressCallback })\n    return new Log(ipfs, identity, { logId, access, entries, sortFn })\n  }\n\n  /**\n   * Create a new log from an Entry instance.\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {Identity} identity The identity instance\n   * @param {Entry|Array<Entry>} sourceEntries An Entry or an array of entries to fetch a log from\n   * @param {Object} options\n   * @param {AccessController} options.access The access controller instance\n   * @param {number} options.length How many entries to include. Default: infinite.\n   * @param {Array<Entry>} options.exclude Entries to not fetch (cached)\n   * @param {function(hash, entry, parent, depth)} [options.onProgressCallback]\n   * @param {Function} options.sortFn The sort function - by default LastWriteWins\n   * @return {Promise<Log>} New Log\n   */\n  static async fromEntry (ipfs, identity, sourceEntries,\n    { access, length = -1, exclude = [], timeout, concurrency, sortFn, onProgressCallback } = {}) {\n    // TODO: need to verify the entries with 'key'\n    const { logId, entries } = await LogIO.fromEntry(ipfs, sourceEntries,\n      { length, exclude, timeout, concurrency, onProgressCallback })\n    return new Log(ipfs, identity, { logId, access, entries, sortFn })\n  }\n\n  /**\n   * Find heads from a collection of entries.\n   *\n   * Finds entries that are the heads of this collection,\n   * ie. entries that are not referenced by other entries.\n   *\n   * @param {Array<Entry>} entries Entries to search heads from\n   * @returns {Array<Entry>}\n   */\n  static findHeads (entries) {\n    var indexReducer = (res, entry, idx, arr) => {\n      var addToResult = e => (res[e] = entry.hash)\n      entry.next.forEach(addToResult)\n      return res\n    }\n\n    var items = entries.reduce(indexReducer, {})\n\n    var exists = e => items[e.hash] === undefined\n    var compareIds = (a, b) => a.clock.id > b.clock.id\n\n    return entries.filter(exists).sort(compareIds)\n  }\n\n  // Find entries that point to another entry that is not in the\n  // input array\n  static findTails (entries) {\n    // Reverse index { next -> entry }\n    var reverseIndex = {}\n    // Null index containing entries that have no parents (nexts)\n    var nullIndex = []\n    // Hashes for all entries for quick lookups\n    var hashes = {}\n    // Hashes of all next entries\n    var nexts = []\n\n    var addToIndex = (e) => {\n      if (e.next.length === 0) {\n        nullIndex.push(e)\n      }\n      var addToReverseIndex = (a) => {\n        /* istanbul ignore else */\n        if (!reverseIndex[a]) reverseIndex[a] = []\n        reverseIndex[a].push(e)\n      }\n\n      // Add all entries and their parents to the reverse index\n      e.next.forEach(addToReverseIndex)\n      // Get all next references\n      nexts = nexts.concat(e.next)\n      // Get the hashes of input entries\n      hashes[e.hash] = true\n    }\n\n    // Create our indices\n    entries.forEach(addToIndex)\n\n    var addUniques = (res, entries, idx, arr) => res.concat(findUniques(entries, 'hash'))\n    var exists = e => hashes[e] === undefined\n    var findFromReverseIndex = e => reverseIndex[e]\n\n    // Drop hashes that are not in the input entries\n    const tails = nexts // For every hash in nexts:\n      .filter(exists) // Remove undefineds and nulls\n      .map(findFromReverseIndex) // Get the Entry from the reverse index\n      .reduce(addUniques, []) // Flatten the result and take only uniques\n      .concat(nullIndex) // Combine with tails the have no next refs (ie. first-in-their-chain)\n\n    return findUniques(tails, 'hash').sort(Entry.compare)\n  }\n\n  // Find the hashes to entries that are not in a collection\n  // but referenced by other entries\n  static findTailHashes (entries) {\n    var hashes = {}\n    var addToIndex = e => (hashes[e.hash] = true)\n    var reduceTailHashes = (res, entry, idx, arr) => {\n      var addToResult = (e) => {\n        /* istanbul ignore else */\n        if (hashes[e] === undefined) {\n          res.splice(0, 0, e)\n        }\n      }\n      entry.next.reverse().forEach(addToResult)\n      return res\n    }\n\n    entries.forEach(addToIndex)\n    return entries.reduce(reduceTailHashes, [])\n  }\n\n  static difference (a, b) {\n    let stack = Object.keys(a._headsIndex)\n    let traversed = {}\n    let res = {}\n\n    const pushToStack = hash => {\n      if (!traversed[hash] && !b.get(hash)) {\n        stack.push(hash)\n        traversed[hash] = true\n      }\n    }\n\n    while (stack.length > 0) {\n      const hash = stack.shift()\n      const entry = a.get(hash)\n      if (entry && !b.get(hash) && entry.id === b.id) {\n        res[entry.hash] = entry\n        traversed[entry.hash] = true\n        entry.next.forEach(pushToStack)\n      }\n    }\n    return res\n  }\n}\n\nmodule.exports = Log\nmodule.exports.Sorting = Sorting\nmodule.exports.Entry = Entry\nmodule.exports.AccessController = AccessController\n"]},"metadata":{},"sourceType":"script"}